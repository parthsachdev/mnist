{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sachd\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the larger model\n",
    "def larger_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(30, (5, 5), input_shape=(1, 28, 28), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(15, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 165s 3ms/step - loss: 0.3925 - acc: 0.8796 - val_loss: 0.0994 - val_acc: 0.9671\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 160s 3ms/step - loss: 0.0955 - acc: 0.9705 - val_loss: 0.0560 - val_acc: 0.9812\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 159s 3ms/step - loss: 0.0691 - acc: 0.9787 - val_loss: 0.0362 - val_acc: 0.9890\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 158s 3ms/step - loss: 0.0561 - acc: 0.9830 - val_loss: 0.0324 - val_acc: 0.9893\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 158s 3ms/step - loss: 0.0477 - acc: 0.9850 - val_loss: 0.0291 - val_acc: 0.9910\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 158s 3ms/step - loss: 0.0439 - acc: 0.9863 - val_loss: 0.0262 - val_acc: 0.9918\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 159s 3ms/step - loss: 0.0383 - acc: 0.9877 - val_loss: 0.0259 - val_acc: 0.9912\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 159s 3ms/step - loss: 0.0347 - acc: 0.9889 - val_loss: 0.0219 - val_acc: 0.9921\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 160s 3ms/step - loss: 0.0327 - acc: 0.9894 - val_loss: 0.0215 - val_acc: 0.9931\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 158s 3ms/step - loss: 0.0277 - acc: 0.9915 - val_loss: 0.0200 - val_acc: 0.9926\n",
      "Large CNN Error: 0.74%\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model = larger_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Large CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
